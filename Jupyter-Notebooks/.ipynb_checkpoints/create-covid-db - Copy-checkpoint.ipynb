{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d853dea8",
   "metadata": {},
   "source": [
    "### Monash Data Analytical Bootcamp - Project 2 Assignment \n",
    "\n",
    "#### Project Team Members:\n",
    "*   Megan Greenhill \n",
    "*   Hesh Kuruppuge\n",
    "*   Jacqueline Xia\n",
    "*   Mike Murphy \n",
    "\n",
    "The John Hopkins University (JHU) Covid data extract component of this assignment is based on the tutorial by B Chen \n",
    "and is used with his permission. The tutorial is located at the following link. \n",
    "\n",
    "*    https://towardsdatascience.com/covid-19-data-processing-58aaa3663f6 \n",
    "    \n",
    "\n",
    "This assignment uses the following Covid19 CSV files which are updated daily and published by John Hopkins University. \n",
    "\n",
    "*    time_series_covid19_confirmed_global.csv................confirmed global Covid_19 cases\n",
    "*    time_series_covid19_deaths_global.csv...................confirmed global Covid_19 deaths\n",
    "*    time_series_covid19_recovered_global.csv................confirmed global Covid_19 recovered \n",
    "\n",
    "It uses the following World Covid Vaccination dataset published by Our World in Data. \n",
    "\n",
    "*    https://ourworldindata.org/covid-vaccinations \n",
    "\n",
    "It uses the following World Population dataset published by Our World in Data. \n",
    "\n",
    "*    https://www.worldometers.info/world-population/population-by-country/ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   import dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from scipy.stats import linregress\n",
    "from urllib.error import HTTPError\n",
    "import numpy as np\n",
    "import wget\n",
    "import time\n",
    "from datetime import datetime\n",
    "#from pandas_profiling import ProfileReport\n",
    "\n",
    "#   the project uses urls / wget downloads in place of API calls are they are not available for the datasets needed\n",
    "\n",
    "# url of the raw csv dataset\n",
    "urls = [\n",
    "    'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv',\n",
    "    'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv',\n",
    "    'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "]\n",
    "[wget.download(url) for url in urls]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77988b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   create dataframes from csv's\n",
    "\n",
    "confirmed_df = pd.read_csv('time_series_covid19_confirmed_global.csv')\n",
    "    \n",
    "deaths_df = pd.read_csv('time_series_covid19_deaths_global.csv')\n",
    "    \n",
    "recovered_df = pd.read_csv('time_series_covid19_recovered_global.csv')\n",
    "\n",
    "confirmed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ac0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfd0cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efd9025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   save DFs to CSVs to do exploratory data analysis\n",
    "confirmed_df.to_csv('exported_conf_df.csv')\n",
    "deaths_df.to_csv('exported_deaths_df.csv')\n",
    "recovered_df.to_csv('exported_recvd_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   use melt() to unpivot DataFrames from current wide format into long format\n",
    "\n",
    "dates = confirmed_df.columns[4:]\n",
    "confirmed_df_long = confirmed_df.melt(\n",
    "    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n",
    "    value_vars=dates, \n",
    "    var_name='Date', \n",
    "    value_name='Confirmed'\n",
    ")\n",
    "deaths_df_long = deaths_df.melt(\n",
    "    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n",
    "    value_vars=dates, \n",
    "    var_name='Date', \n",
    "    value_name='Deaths'\n",
    ")\n",
    "recovered_df_long = recovered_df.melt(\n",
    "    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n",
    "    value_vars=dates, \n",
    "    var_name='Date', \n",
    "    value_name='Recovered'\n",
    ")\n",
    "confirmed_df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22427bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_df_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f796a",
   "metadata": {},
   "source": [
    "#### Remove recovered data for Canada due to mismatch issue\n",
    "*    Canada recovered data is counted for the whole Country instead of by Province/State which is how Canada \n",
    "*    and the rest of the world count data for \"Confirmed Cases\" and \"Deaths\".\n",
    "\n",
    "#### We considered apportioning recovered data for the whole country in the same ratio as confirmed cases. \n",
    "#### This is arbitrarily altering data from a source and is considered bad practice so we did not do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   remove Canada recovered data\n",
    "recovered_df_long = recovered_df_long[recovered_df_long['Country/Region']!='Canada']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6296d2a",
   "metadata": {},
   "source": [
    "####   merge the 3 data frames one after another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad22c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#   merge confirmed_df_long and deaths_df_long\n",
    "full_table = confirmed_df_long.merge(\n",
    "  right=deaths_df_long, \n",
    "  how='left',\n",
    "  on=['Province/State', 'Country/Region', 'Date', 'Lat', 'Long']\n",
    ")\n",
    "\n",
    "#    merge full_table and recovered_df_long\n",
    "full_table = full_table.merge(\n",
    "  right=recovered_df_long, \n",
    "  how='left',\n",
    "  on=['Province/State', 'Country/Region', 'Date', 'Lat', 'Long']\n",
    ")\n",
    "\n",
    "full_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Check Canada data in \"full_table\" - \"recovered\" should be 0 and check of CSV file confirms it is \n",
    "full_table.to_csv('full_table_can_recvd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ffdf1",
   "metadata": {},
   "source": [
    "####   Data Cleansing\n",
    "*    1. converting date from string to datetime\n",
    "*    2. replacing missing value NaN with zeroes\n",
    "*    3. coronavirus cases reported from 3 cruise ships should be treated differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dfc007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   1 converting date from string to datetime\n",
    "full_table['Date'] = pd.to_datetime(full_table['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5330f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00a15dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   2 replacing missing values NaN\n",
    "#   detect missing values NaN \n",
    "full_table.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   replace 'recovered' NaNs with zero\n",
    "full_table['Recovered'] = full_table['Recovered'].fillna(0)\n",
    "full_table['Recovered']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034ac809",
   "metadata": {},
   "source": [
    "####   3 coronavirus cases reported from 3 cruise ships should be treated differently\n",
    "*    Cases reported from cruise ships: Grand Princess, Diamond Princess and MS Zaandam need to be extracted and \n",
    "*    treated differently due to Province/State and Country/Region mismatch over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80affc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   extract data for these ships \n",
    "ship_rows = full_table['Province/State'].str.contains('Grand Princess') | full_table['Country/Region'].str.contains('Diamond Princess') | full_table['Country/Region'].str.contains('MS Zaandam')\n",
    "full_ship = full_table[ship_rows]\n",
    "\n",
    "#   remove data for these ships \n",
    "full_table = full_table[~(ship_rows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   check \"full_table\" to ensure its integrity\n",
    "full_table.to_csv('full_table_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f07dd6",
   "metadata": {},
   "source": [
    "#### Calculate the number of Active Cases \n",
    "    *Active Cases = Confirmed Cases - Deaths - Recovered Cases \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b340bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    calculate active cases = confirmed - deaths - recovered\n",
    "full_table['Active'] = full_table['Confirmed'] - full_table['Deaths'] - full_table['Recovered']\n",
    "full_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeaa47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   aggregate data into Country/Region and group by Date and Country/Region\n",
    "\n",
    "full_grouped = full_table.groupby(['Date', 'Country/Region'])['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()\n",
    "full_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de48194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   calculate daily New cases, New deaths and New recovered by deducting the corresponding accumulative data on the previous day\n",
    "#   new cases \n",
    "temp = full_grouped.groupby(['Country/Region', 'Date', ])['Confirmed', 'Deaths', 'Recovered']\n",
    "temp = temp.sum().diff().reset_index()\n",
    "mask = temp['Country/Region'] != temp['Country/Region'].shift(1)\n",
    "temp.loc[mask, 'Confirmed'] = np.nan\n",
    "temp.loc[mask, 'Deaths'] = np.nan\n",
    "temp.loc[mask, 'Recovered'] = np.nan\n",
    "\n",
    "#   renaming columns\n",
    "temp.columns = ['Country/Region', 'Date', 'New cases', 'New deaths', 'New recovered']\n",
    "\n",
    "#   merging new values\n",
    "full_grouped = pd.merge(full_grouped, temp, on=['Country/Region', 'Date'])\n",
    "\n",
    "#   filling na with 0\n",
    "full_grouped = full_grouped.fillna(0)\n",
    "\n",
    "#   fixing data types\n",
    "cols = ['New cases', 'New deaths', 'New recovered']\n",
    "full_grouped[cols] = full_grouped[cols].astype('int')\n",
    "\n",
    "full_grouped['New cases'] = full_grouped['New cases'].apply(lambda x: 0 if x<0 else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589bf314",
   "metadata": {},
   "source": [
    "####   Final output is data sorted by Date and Country/Region ascending where: -\n",
    "*    Confirmed Cases, Deaths, Recovered and Active are cumulative data for the entire period, and,\n",
    "*    New cases, New deaths and New Recovered are daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51053f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Final data frame\n",
    "full_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0681b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   convert dataframe to a csv file for backup\n",
    "full_grouped.to_csv('exported_CSVs/covid_cases.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d54a3",
   "metadata": {},
   "source": [
    "#### Check data for Australia against JHU Daily Replorts to confirm that it is correct \n",
    "#### Data is correct as at 07/02/2022 - 2,727,260 confirmed cases & 4,200 confirmed deaths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc800c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   select Oz to check that data is correct\n",
    "full_grouped_oz = full_grouped.loc[full_grouped[\"Country/Region\"] == \"Australia\"]\n",
    "full_grouped_oz\n",
    "\n",
    "# Check data for Australia against JHU Daily Replorts to confirm that it is correct. \n",
    "# Data is correct as at 07/02/2022 08:00 - 2,727,260 confirmed cases & 4,200 confirmed deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe386b4",
   "metadata": {},
   "source": [
    "#### VACCINATION DATASET SOURCED FROM OUR WORLD IN DATA AT THE FOLLOWING LINK\n",
    "*    https://ourworldindata.org/covid-vaccinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5776f75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#   read the vaccination dataset - csv file into a dataframe\n",
    "vacc_data_df = pd.read_csv('owid-covid-data.csv')\n",
    "vacc_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dafe30",
   "metadata": {},
   "source": [
    "#### Create data frame with just people vaccinated data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4dbc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_data_df = vacc_data_df[[\"iso_code\", \"continent\", \"location\", \"date\", \"people_vaccinated_per_hundred\",\n",
    "                             \"people_fully_vaccinated_per_hundred\", \"total_boosters_per_hundred\"]]\n",
    "vacc_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   detect missing values NaN \n",
    "vacc_data_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0098918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   replace NaNs with zero\n",
    "vacc_data_df['people_vaccinated_per_hundred'] = vacc_data_df['people_vaccinated_per_hundred'].fillna(0)\n",
    "vacc_data_df['people_fully_vaccinated_per_hundred'] = vacc_data_df['people_vaccinated_per_hundred'].fillna(0)\n",
    "vacc_data_df['total_boosters_per_hundred'] = vacc_data_df['total_boosters_per_hundred'].fillna(0)\n",
    "vacc_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   data cleansing'Country/Region].replace(['United States'], 'US')\n",
    "vacc_data_df['location'] = vacc_data_df['location'].replace(['United States'],'US')\n",
    "vacc_data_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f8d2bd",
   "metadata": {},
   "source": [
    "#### people_vaccinated_per_hundred is non zero if people have had one vaccination, so we can calculate the \n",
    "#### unvaccinated as follows: people_not_vaccinated_per_hundred = 100 - people_vaccinated_per_hundred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e48cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   now calculate people_not_vaccinated_per_hundred = 100 - people_vaccinated_per_hundred \n",
    "vacc_data_df['people_not_vaccinated_per_hundred'] = 0\n",
    "vacc_data_df['people_not_vaccinated_per_hundred'] = np.where(vacc_data_df['people_vaccinated_per_hundred'] != 0,\n",
    "                        100 - vacc_data_df['people_vaccinated_per_hundred'], vacc_data_df['people_not_vaccinated_per_hundred'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ac0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleansed vaccination data to a CSV for backup\n",
    "vacc_data_df.to_csv('exported_CSVs/vaccinations.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20123a5",
   "metadata": {},
   "source": [
    "#### WORLD POPULATION DATASET AS AT 31/12/2020 SOURCED FROM THE FOLLOWING LINK\n",
    "*    https://www.worldometers.info/world-population/population-by-country/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520215d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   read the world population dataset - csv file into a dataframe\n",
    "pop_data_df = pd.read_csv('world_population.csv')\n",
    "pop_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   detect missing values NaN \n",
    "pop_data_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38847e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   replace NaNs with zero\n",
    "pop_data_df['1960'] = pop_data_df['1960'].fillna(0)\n",
    "pop_data_df['2016'] = pop_data_df['2016'].fillna(0)\n",
    "pop_data_df['2017'] = pop_data_df['2017'].fillna(0)\n",
    "pop_data_df['2018'] = pop_data_df['2018'].fillna(0)\n",
    "pop_data_df['2019'] = pop_data_df['2019'].fillna(0)\n",
    "pop_data_df['2020'] = pop_data_df['2020'].fillna(0)\n",
    "pop_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c14c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleansed population data to a CSV for backup\n",
    "pop_data_df.to_csv('exported_CSVs/world_population.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06778788",
   "metadata": {},
   "source": [
    "#### Create dataframe for Country Codes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy OWID Vaccination dataframe, as we want to use OWID country codes\n",
    "country_codes = vacc_data_df[[\"iso_code\",\"location\",\"continent\"]]\n",
    "country_codes_cleaned = country_codes.drop_duplicates(subset=[\"iso_code\"])\n",
    "country_codes = country_codes_cleaned.rename(columns={\"iso_code\":\"country_id\",\n",
    "                                              \"location\":\"country_name\",\n",
    "                                              \"continent\":\"continent_name\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e018bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Africas to match population dataframe\n",
    "africa_eastern = {'country_id': 'AFE', 'country_name': 'Africa Eastern and Southern', 'continent_name': 'Africa'}\n",
    "africa_western = {'country_id': 'AFW', 'country_name': 'Africa Western and Central', 'continent_name': 'Africa'}\n",
    "country_codes = country_codes.append(africa_eastern, ignore_index = True)\n",
    "country_codes = country_codes.append(africa_western, ignore_index = True)\n",
    "country_codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb8069",
   "metadata": {},
   "source": [
    "#### Edit full_grouped covid case dataframe to include country ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ece3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_grouped_copy = full_grouped.copy()\n",
    "full_grouped_copy = full_grouped_copy.rename(columns={\"Country/Region\":\"country_name\"})\n",
    "full_grouped_reformatted = pd.merge(country_codes,full_grouped_copy,on=\"country_name\")\n",
    "full_grouped_reformatted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f0139",
   "metadata": {},
   "source": [
    "### Change structure of dataframes to match structure of tables created in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f00572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index of country codes dataframe, and remove null index row\n",
    "country_codes = country_codes.set_index(\"country_id\")\n",
    "country_codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bdfe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covid Cases table\n",
    "# Copy only the columns needed into a new DataFrame.\n",
    "covid_cases = full_grouped_reformatted[[\"country_id\",\"Date\",\"Confirmed\",\"Deaths\",\"Recovered\",\"Active\",\"New cases\",\"New deaths\",\"New recovered\"]]\n",
    "\n",
    "# Rename columns to fit the tables created in the database.\n",
    "covid_cases = covid_cases.rename(columns={\"Date\":\"date\",\n",
    "                                          \"Confirmed\":\"confirmed\",\n",
    "                                          \"Deaths\":\"deaths\",\n",
    "                                          \"Recovered\":\"recovered\",\n",
    "                                          \"Active\":\"active\",\n",
    "                                          \"New cases\":\"new_cases\",\n",
    "                                          \"New deaths\":\"new_deaths\",\n",
    "                                          \"New recovered\":\"new_recovered\"})\n",
    "covid_cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ab545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleansed covid-cases data to a CSV for backup\n",
    "covid_cases.to_csv('exported_CSVs/covid_cases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population table\n",
    "# Copy only the columns needed into a new DataFrame.\n",
    "population = pop_data_df[[\"Country Code\",\"2020\"]]\n",
    "\n",
    "# Rename columns to fit the tables created in the database.\n",
    "population = population.rename(columns={\"Country Code\":\"country_id\",\n",
    "                                          \"2020\":\"population\"})\n",
    "population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8956fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaccinations table\n",
    "# Copy only the columns needed into a new DataFrame.\n",
    "vaccinations = vacc_data_df[[\"iso_code\",\"date\",\"people_vaccinated_per_hundred\", \"people_fully_vaccinated_per_hundred\",\n",
    "                             \"total_boosters_per_hundred\", \"people_not_vaccinated_per_hundred\"]]\n",
    "\n",
    "# Rename columns to fit the tables created in the database.\n",
    "vaccinations = vaccinations.rename(columns={\"iso_code\":\"country_id\",\n",
    "                                          \"people_vaccinated_per_hundred\":\"vaccinated_per_hundred\",\n",
    "                                          \"people_fully_vaccinated_per_hundred\":\"fully_vaccinated_per_hundred\",\n",
    "                                          \"total_boosters_per_hundred\":\"boosted_per_hundred\",\n",
    "                                          \"people_not_vaccinated_per_hundred\":\"not-vaccinated_per_hundred\"})\n",
    "vaccinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f57291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleansed vaccinations data to a CSV for backup\n",
    "vaccinations.to_csv('exported_CSVs/vaccinations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de274835",
   "metadata": {},
   "source": [
    "### Load tables to Integrated Covid View database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e621afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database connection\n",
    "rds_connection_string = \"postgres:meg221196@localhost:5432/integrated_covid_view_db\"\n",
    "engine = create_engine(f'postgresql://{rds_connection_string}')\n",
    "\n",
    "# Confirm database tables\n",
    "engine.table_names()\n",
    "\n",
    "# Load dataframes to database tables\n",
    "country_codes.to_sql(name='country_codes', con=engine, if_exists='append', index=False)\n",
    "covid_cases.to_sql(name='covid_cases', con=engine, if_exists='append', index=False)\n",
    "population.to_sql(name='population', con=engine, if_exists='append', index=False)\n",
    "vaccinations.to_sql(name='vaccinations', con=engine, if_exists='append', index=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d99a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
